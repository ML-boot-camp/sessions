{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415e7d8e",
   "metadata": {},
   "source": [
    "# ðŸ Practice nÂ°4: classification\n",
    "The objective of this session is to learn about classification task. You will have to\n",
    "build a new model only using the text review.\n",
    "\n",
    "In order to apply classification models, we need to change the target definition. We\n",
    "will divide the reviews into good or bad using the rating.\n",
    "\n",
    "So our goal is to have a model, a function, that takes text as input and output a\n",
    "label/class (good review or bad review).\n",
    "\n",
    "$$f(text) = label$$\n",
    "\n",
    "The data are the same as those used for the regression (*source* [*ratebeer dataset description*](https://snap.stanford.edu/data/web-RateBeer.html)).\n",
    "\n",
    "\n",
    "Here are the main steps of the notebook :\n",
    "\n",
    "1. What is classification ?\n",
    "2. Focus on logistic regression\n",
    "3. Preparation\n",
    "4. Binary target definition\n",
    "5. Text cleaning\n",
    "6. Modelling\n",
    "  - 6.1 First model using CountVectorizer\n",
    "  - 6.2 Choose the right metrics\n",
    "  - 6.3 Second model using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e146522",
   "metadata": {},
   "source": [
    "## 1. What is classification ?\n",
    "\n",
    "Classification in machine learning consists of mathematical methods that allow to\n",
    "predict a discrete outcome (y) based on the value of one or more predictor variables\n",
    "(x).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5263df",
   "metadata": {},
   "source": [
    "![](https://ml-boot-camp.github.io/sessions/10-Tutorials/files/regression-vs-classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67325ecb",
   "metadata": {},
   "source": [
    "\n",
    "There are several types of classification :\n",
    "\n",
    "\n",
    "* **Binary classification**: the task of classifying the data into two groups (each\n",
    "called class).\n",
    "> Example: an email can be classified as belonging to one of two classes: \"spam\" and\n",
    "\"not spam\".\n",
    "\n",
    "* **Multi-class classification**: the task of classifying the data into N groups\n",
    "(N > 2).\n",
    "> Example: an image can be classified as belonging to one of N classes: \"cat\", \"dog\",\n",
    "\"cow\" or \"fish\".\n",
    "\n",
    "* **Multi-label classification**: this is a generalization of multi-class\n",
    "classification problem where an instance can be assigned to multiple classes.\n",
    "> Example: a movie can be classified as belonging to one or more classes: \"action\",\n",
    "\"adventure\", \"thriller\" or all simultaneously.\n",
    "\n",
    "\n",
    "In this session, we will focus on the **Binary classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4a9eb",
   "metadata": {},
   "source": [
    "## 2. Focus on logistic regression\n",
    "\n",
    "As seen in the last session, we can represent the link between the explicatives\n",
    "variables and the target to be predicted as follows\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$$\n",
    "\n",
    "The difference here is that the target is not a continous variable (rating) but a\n",
    "discrete one (good review / bad review). If we limit ourselves to this model, the\n",
    "linear combination of each input will give an unbounded number that does not allow us\n",
    "to classify the review into good or bad.\n",
    "\n",
    "To transform the number provided by the linear combination into a classification, we\n",
    "use a function called `sigmoid function` which has the interesting property of\n",
    "transforming the numbers passed inside into numbers between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240f021",
   "metadata": {},
   "source": [
    "![](https://ml-boot-camp.github.io/sessions/10-Tutorials/files/sigmoid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f6f56",
   "metadata": {},
   "source": [
    "After passing the linear combination through this function, the output will be\n",
    "considered as a probability $P$ and using a threshold (0.5 in general), the review\n",
    "can be classified as bad review, if $P < 0.5$, or good review, if $P >= 0.5$.\n",
    "\n",
    "_This threshold can be modified in some contexts_\n",
    "\n",
    "Then during the training phase, we will compute the parameters Î² in order to optimize\n",
    "the `Maximum Likelihood` i.e., for a given bad review, we want the probalility\n",
    "estimated by our model to be minimal and for a given good review, we want the\n",
    "probalility estimated by our model to be maximal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391913b5",
   "metadata": {},
   "source": [
    "## 3. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0549c",
   "metadata": {},
   "source": [
    "### Install & import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "nltk.download('stopwords')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c9adb",
   "metadata": {},
   "source": [
    "### Read remote dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0dd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"https://github.com/ML-boot-camp/ratebeer/raw/master/data/ratebeer_sample_enriched.parquet\"\n",
    "df_full = pd.read_parquet(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29527dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163c2d8",
   "metadata": {},
   "source": [
    "## 4. Binary target definition\n",
    "\n",
    "Filter the data using only 1000 reviews and then explore some reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "N_rows = 1000\n",
    "df = df_full[[\"text\", \"rating\", \"is_good\"]].sample(N_rows, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83284407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some text reviews\n",
    "\n",
    "print(\"GUESS THE RATING ?\")\n",
    "df_example = df.sample(n=1)\n",
    "df_example.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b56ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RATING: {df_example.rating.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673be118",
   "metadata": {},
   "source": [
    "To begin with a binary classification problem, we will bin the target into 2 classes:\n",
    "bad review and good review\n",
    "\n",
    "First, look at the target distribution and choose a threshlold to identify good\n",
    "reviews from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the target distribution\n",
    "df.rating.astype(int).plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3185461",
   "metadata": {},
   "source": [
    "You can play with the **rating_threshold** and look at the new target distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary target and display the target distribution\n",
    "rating_threshold = 16 # LINE TO BE REMOVED FOR STUDENTS\n",
    "(df.rating >= rating_threshold).astype(int).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3335c2",
   "metadata": {},
   "source": [
    "Usually the threshold is defined by looking manually at the data: annotating a few\n",
    "reviews as \"good\" or \"bad\" and see which ratings they had.\n",
    "E.g: on google maps a \"good\" review is above 4 stars (out of 5 stars).\n",
    "For simplicity, here we'll use the `is_good` binary target defined during the data\n",
    "engineering phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c7a60",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create a binary target and display the target distribution\n",
    "rating_threshold = df.rating.median() # LINE TO BE REMOVED FOR STUDENTS\n",
    "(df.rating >= rating_threshold).astype(int).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f0abe6",
   "metadata": {},
   "source": [
    "## 5. Text cleaning\n",
    "\n",
    "#### From text reviews to numerical vectors\n",
    "\n",
    "Before training some models, the first step is to transform text into numbers :\n",
    "\n",
    "from\n",
    "```\n",
    "f(raw_text) = rating_classe\n",
    "```\n",
    "\n",
    "to\n",
    "```\n",
    "f(numerical_vector_representing_text) = rating_classe\n",
    "```\n",
    "\n",
    "Indeed, we can't direclty feed an algortihm with text.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "Wow, that beer is SOOOO good :O !!\n",
    "```\n",
    "\n",
    "must be transformed to something like:\n",
    "```\n",
    "[3, 4, 21, 0, 0, 8, 19]\n",
    "```\n",
    "where the values of the vector contain the meaning of the text. Knowing that the\n",
    "closer texts are in terms of meaning, the more closed their vector representation is\n",
    "too. Moreover, it is often more convenient to convert texts of different sizes into\n",
    "vectors of fixed size.\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "\"Wow, that beer is SOOOO good :O !!\"\n",
    "-> characters : 34\n",
    "-> vector (1x7) : [3, 4, 21, 0, 0, 8, 19]\n",
    "```\n",
    "```\n",
    "\"This beer is very tasty\"\n",
    "-> characters : 23\n",
    "-> vector (1x7) : [3, 4, 20, 0, 0, 7, 19]\n",
    "```\n",
    "But:\n",
    "```\n",
    "\"It's not a beer, just motor oil at best.\"\n",
    "-> characters : 40\n",
    "-> vector (1x7) : [0, 4, 1, 12, 14, 0, 0]\n",
    "```\n",
    "\n",
    "#### From raw text reviews to clean list of words\n",
    "\n",
    "Before converting text to numerical vector, the first step is to clean the text to\n",
    "keep only the pertinent information.\n",
    "\n",
    "Here are the following cleaning steps that we will apply on the reviews:\n",
    "1. Convert letter to lowercase\n",
    "```\n",
    "\"Wow, that beer is SOOOO good :O !!\" -> \"wow, that beer is soooo good :o !!\"\n",
    "```\n",
    "2. Remove the punctuation letter to lowercase\n",
    "```\n",
    "\"wow, that beer is soooo good :o !!\" -> \"wow that beer is soooo good\"\n",
    "```\n",
    "3. Transform the text into tokens\n",
    "```\n",
    "\"wow that beer is soooo good\" -> [\"wow\", \"that\", \"beer\", \"is\", \"soooo\", \"good\"]\n",
    "```\n",
    "4. Remove the stopwords, the most common english words that often bring noise to the\n",
    "models.\n",
    "```\n",
    "[\"wow\", \"that\", \"beer\", \"is\", \"soooo\", \"good\"] -> [\"wow\", \"beer\", \"soooo\", \"good\"]\n",
    "```\n",
    "\n",
    "5. To go further, some techniques can be used to reduce the forms of each word into a\n",
    "common base or root. This can be done with:\n",
    "\n",
    "(1) **Stemming** is the process of eliminating affixes (suffixed, prefixes, infixes,\n",
    "circumfixes) from a word in order to obtain a word stem.\n",
    "\n",
    "> am, are, is  $\\Rightarrow$  be\n",
    "\n",
    "(2) **Lemmatization** is related to stemming, differing in that lemmatization is able\n",
    "to capture canonical forms based on a word's lemma.\n",
    "\n",
    "> book, books, book's, book'  $\\Rightarrow$  book\n",
    "\n",
    "_The steps presented here are just the most basic, many different things can be\n",
    "applied to the cleaning part of the text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc2aad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def convert_text_to_lowercase(df, colname):\n",
    "    df[colname] = (\n",
    "        df[colname]\n",
    "        .str.lower() # LINE TO BE REMOVED FOR STUDENTS\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def not_regex(pattern):\n",
    "        return r\"((?!{}).)\".format(pattern)\n",
    "\n",
    "def remove_punctuation(df, colname):\n",
    "    df[colname] = df[colname].str.replace(\"\\n\", \" \")\n",
    "    df[colname] = df[colname].str.replace(\"\\r\", \" \")\n",
    "    alphanumeric_characters_extended = \"(\\\\b[-/]\\\\b|[a-zA-Z0-9])\"\n",
    "    df[colname] = df[colname].str.replace(not_regex(alphanumeric_characters_extended), \" \")\n",
    "    return df\n",
    "\n",
    "def tokenize_sentence(df, colname):\n",
    "    df[colname] = df[colname].str.split()\n",
    "    return df\n",
    "\n",
    "def remove_stop_words(df, colname):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    df[colname] = df[colname].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    return df\n",
    "\n",
    "def reverse_tokenize_sentence(df, colname):\n",
    "    df[colname] = df[colname].map(lambda word: \" \".join(word))\n",
    "    return df\n",
    "\n",
    "\n",
    "def text_cleaning(df, colname):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. convert text to lowercase\n",
    "    2. remove punctuation and new line characters \"\\n\"\n",
    "    3. Tokenize sentences\n",
    "    4. Remove all stopwords\n",
    "    5. convert tokenized text to text\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        df\n",
    "        .pipe(convert_text_to_lowercase, colname) # LINE TO BE REMOVED FOR STUDENTS\n",
    "        .pipe(remove_punctuation, colname) # LINE TO BE REMOVED FOR STUDENTS\n",
    "        .pipe(tokenize_sentence, colname) # LINE TO BE REMOVED FOR STUDENTS\n",
    "        .pipe(remove_stop_words, colname) # LINE TO BE REMOVED FOR STUDENTS\n",
    "        .pipe(reverse_tokenize_sentence, colname) # LINE TO BE REMOVED FOR STUDENTS\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data cleaning\n",
    "df_cleaned = text_cleaning(\n",
    "    df, # LINE TO BE REMOVED FOR STUDENTS\n",
    "    \"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2712089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control the cleaning\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f601a",
   "metadata": {},
   "source": [
    "We still have to transform the list of tokens to a fixed size numerical vector\n",
    "\n",
    "For that, we will use 2 very common techniques : CountVectorizer and TF-IDF\n",
    "\n",
    "**1) CountVectorizer:**\n",
    "\n",
    "**CountVectorizer** is used to convert a collection of text documents to a vector of\n",
    "token counts. \n",
    "\n",
    "Example:\n",
    "```\n",
    "[\"beer\", \"most\", \"tasty\", \"beer\", \"world\"]\n",
    "```\n",
    "\n",
    "Will be transformed into â¬‡\n",
    "\n",
    "| beer | most | tasty | world |\n",
    "|------|------|-------|-------|\n",
    "| 2    | 1    | 1     | 1     |\n",
    "\n",
    "In practice, you have to define a vocabulary size and each text will be transform into\n",
    "a vector of size [1 x vocabulary size]. Consequently, zeros will be added to the\n",
    "vector for each word present in the corpus vocabulary but missing in the specific\n",
    "review. \n",
    "The vocabulary space is defined using term frequency across the corpus: the most\n",
    "frequent words are kept.\n",
    "\n",
    "**2) TF-IDF (optional):**\n",
    "\n",
    "**TF-IDF** or **term frequencyâ€“inverse document frequency**, is a numerical statistic\n",
    "that is intended to reflect how important a word is to reflect how important a word is\n",
    "to a document in a collection or corpus.\n",
    "\n",
    "**TF: Term Frequency**, which measures how frequently a term occurs in a document.\n",
    "Since every document is different in length, it is possible that a term would appear\n",
    "much more times in long documents than shorter ones. Thus, the term frequency is often\n",
    "divided by the document length (aka. the total number of terms in the document) as a\n",
    "way of normalization: \n",
    "     \n",
    "```\n",
    "TF(t) = (Nbr of times term t appears in a document) / (Total nbr of terms in the\n",
    "document)\n",
    "```\n",
    "   \n",
    "**IDF: Inverse Document Frequency**, which measures how important a term is. While\n",
    "computing TF, all terms are considered equally important. However it is known that\n",
    "certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have\n",
    "little importance. Thus we need to weigh down the frequent terms while scale up the\n",
    "rare ones, by computing the following: \n",
    "     \n",
    "```\n",
    "IDF(t) = log(Total number of documents / Number of documents with term t in it)\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider a document containing 100 words wherein the word _book_ appears 3 times. The\n",
    "term frequency (i.e., tf) for cat is:\n",
    "```\n",
    "TF(t) = (Nbr of times term t appears in a document) / (Total nbr of terms in the\n",
    "document)\n",
    "      = 3 / 100\n",
    "      = 0.03\n",
    "```\n",
    "Now, assume we have 10 million documents and the word _book_ appears in one thousand\n",
    "of these. Then, the inverse document frequency (i.e., idf) is calculated as\n",
    "```\n",
    "IDF(t) = log(Total number of documents / Number of documents with term t in it)\n",
    "       = log(10,000,000 / 1,000)\n",
    "       = 4\n",
    "```\n",
    "Thus, the Tf-idf weight is the product of these quantities:\n",
    "```\n",
    "Tf-IDF = TF(t) * IDF(t)\n",
    "       = 0.03 * 4\n",
    "       = 0.12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44539e7a",
   "metadata": {},
   "source": [
    "## Split the data into train/test sets\n",
    "\n",
    "Before applying these transormation on the text, we will just split the data for the\n",
    "modelling part.\n",
    "\n",
    "Keep 20% of the data for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"is_good\" # LINE TO BE REMOVED FOR STUDENTS\n",
    "FEATURE = \"text\" # LINE TO BE REMOVED FOR STUDENTS\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_cleaned[FEATURE], # LINE TO BE REMOVED FOR STUDENTS\n",
    "    df_cleaned[TARGET], # LINE TO BE REMOVED FOR STUDENTS\n",
    "    test_size=0.2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1b738",
   "metadata": {},
   "source": [
    "## 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26892b04",
   "metadata": {},
   "source": [
    "### 6.1 First model using CountVectorizer\n",
    "\n",
    "Transform the text reviews into numerical vectors by counting the number of words in each reviews. Use the `scikit-learn` library.\n",
    "\n",
    "In order not to bring information from the train set into the test set, you must train the `CountVectorizer` on the train set and apply it to the test set.\n",
    "\n",
    "Hint:\n",
    " - [`sklearn.feature_extraction.text.CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size to 100\n",
    "count_vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    max_features=100 # LINE TO BE REMOVED FOR STUDENTS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the CountVectorizer and check the results on some rows\n",
    "count_vectorizer.fit(x_train)\n",
    "\n",
    "x_train_features = count_vectorizer.transform(x_train).toarray()\n",
    "x_test_features = count_vectorizer.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee78ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b079e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2d097",
   "metadata": {},
   "source": [
    "The next step is to define the model that will use in input the vectors from the the\n",
    "`CountVectorizer`. We will use a logistic regression model, using again the\n",
    "`scikit-learn` library.\n",
    "\n",
    "In order to produce cleaner code, we can combine these 2 steps (CountVectorizer and\n",
    "Logistic regression) into a single pipeline.\n",
    "\n",
    "- Initialize the `CountVectorizer`\n",
    "- Initialize the `LogisticRegression`\n",
    "- Define your `Pipeline` object with these 2 steps\n",
    "- Fit the `Pipeline`\n",
    "\n",
    "Hint:\n",
    "- [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc555b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    max_features=100\n",
    "    )\n",
    "\n",
    "# Initialize the logistic regression\n",
    "logit = LogisticRegression(solver=\"lbfgs\", verbose=2, n_jobs=-1)\n",
    "\n",
    "# Combine them into a Pipeline object\n",
    "pipeline_cv = Pipeline([\n",
    "    (\"vectorizer\", count_vectorizer), # LINE TO BE REMOVED FOR STUDENTS\n",
    "    (\"model\", logit)]) # LINE TO BE REMOVED FOR STUDENTS\n",
    "\n",
    "# Fit the Pipeline\n",
    "pipeline_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1d022",
   "metadata": {},
   "source": [
    "Now you can make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred_cv = pipeline_cv.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d3ed8",
   "metadata": {},
   "source": [
    "How to evaluate our model ? \n",
    "\n",
    "`Accuracy` is the most intuitive performance measure and it is simply a ratio of\n",
    "correctly predicted observation to the total observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "print(f\"model accuracy : {accuracy_score(y_pred_cv, y_test)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3fc25",
   "metadata": {},
   "source": [
    "What is you opinion about the `accuracy` score ?\n",
    "\n",
    "One may think that, if we have high accuracy then our model is best. Yes, accuracy is\n",
    "a great measure but only when you have symmetric datasets where values of false\n",
    "positive and false negatives are almost same. Therefore, you have to look at other\n",
    "parameters to evaluate the performance of your model.\n",
    "\n",
    "One might think that if we have high accuracy, our model is the best. Yes, accuracy is\n",
    "an excellent measure, but only when you have balanced data (i.e. an equivalent\n",
    "representation of each class in the data).\n",
    "\n",
    "Let's do a test with a reference model to show how accuracy can be a source of error \n",
    "when evaluating a model: Create a model that predict everytime the most frequent class\n",
    "and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: predict the most-frequent class\n",
    "y_pred_baseline = [y_test.mode()[0]] * len(y_test)\n",
    "\n",
    "# Compute accuracy\n",
    "print(f\"model baseline accuracy : {accuracy_score(y_pred_baseline, y_test)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4870471",
   "metadata": {},
   "source": [
    "Accuracy are closed, but the last model is completely idiot !\n",
    "\n",
    "In case of an imbalanced target (let's say 99% zeros), the accuracy of this dumb\n",
    "model will be 99% !\n",
    "\n",
    "Therefore, you need to look at other metrics to evaluate the performance of your\n",
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed46a2",
   "metadata": {},
   "source": [
    "![](https://ml-boot-camp.github.io/sessions/10-Tutorials/files/confusion-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc13f7",
   "metadata": {},
   "source": [
    "### 6.2 Choose the right metrics\n",
    "\n",
    "We need now define other metrics to evaluate our model.\n",
    "\n",
    "- **True Positives** (TP): these are the correctly predicted positive values which\n",
    "means that the value of actual class is yes and the value of predicted class is also\n",
    "yes.\n",
    "\n",
    "- **True Negatives** (TN): these are the correctly predicted negative values which\n",
    "means that the value of actual class is no and value of predicted class is also no.\n",
    "\n",
    "- **False Positives** (FP): when actual class is no and predicted class is yes.\n",
    "\n",
    "- **False Negatives** (FN): when actual class is yes but predicted class in no.\n",
    "\n",
    "- **Accuracy**: the ratio of correctly predicted observation to the total\n",
    "observations.\n",
    "> Accuracy = $\\frac{TP+TN}{TP+FP+FN+TN}$\n",
    "\n",
    "- **Precision**: Precision is the ratio of correctly predicted positive observations\n",
    "to the total predicted positive observations. High precision relates to the low false\n",
    "positive rate.\n",
    "> Precision = $\\frac{TP}{TP+FP}$\n",
    "\n",
    "- **Recall (Sensitivity)**: Recall is the ratio of correctly predicted positive \n",
    "observations to the all observations in actual class - yes.\n",
    "> Recall = $\\frac{TP}{TP+FN}$\n",
    "\n",
    "- **F1 score**: F1 Score is the weighted average of Precision and Recall. Therefore, \n",
    "this score takes both false positives and false negatives into account. Intuitively it\n",
    "is not as easy to understand as accuracy, but F1 is usually more useful than accuracy,\n",
    "especially if you have an uneven class distribution.\n",
    "> F1 Score = $2* \\frac{Recall * Precision}{Recall + Precision}$\n",
    "\n",
    "Let's now compare again our 2 models !\n",
    "\n",
    "First, plot the confusion matrix, the precision, recall and f1 score for each model.\n",
    "You can also print the classification report of scikit learn that sums up the main\n",
    "classification metrics.\n",
    "\n",
    "Hint:\n",
    "- [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "- [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "- [`sklearn.metrics.precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "- [`sklearn.metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    "- [`sklearn.metrics.classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "print(f\"Confusion matrix of the first model: \\n {confusion_matrix(y_test, y_pred_cv)}\")\n",
    "print(f\"Confusion matrix of the baseline model: \\n {confusion_matrix(y_test, y_pred_baseline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the first model\n",
    "print(f\"first model precision : {precision_score(y_pred_cv, y_test):.{3}f}%\")\n",
    "print(f\"first model recall    : {recall_score(y_pred_cv, y_test)}%\")\n",
    "print(f\"first model f1 score  : {f1_score(y_pred_cv, y_test):.{3}f}%\\n\")\n",
    "\n",
    "# Evaluate the baseline model\n",
    "print(f\"baseline model precision : {precision_score(y_pred_baseline, y_test)}%\")\n",
    "print(f\"baseline model recall    : {recall_score(y_pred_baseline, y_test)}%\")\n",
    "print(f\"baseline model f1 score  : {f1_score(y_pred_baseline, y_test)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(\n",
    "    y_test, y_pred_cv # LINE TO BE REMOVED FOR STUDENTS\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eecc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bcdfbe",
   "metadata": {},
   "source": [
    "### 6.3 Second model using TF-IDF Vectorizer (optional)\n",
    "\n",
    "In this last section, you will use a better approach in term of vectorization: TF-IDF\n",
    "\n",
    "Scikit-learn provide the `TfidfVectorizer` that can be used in the same way as\n",
    "`CountVectorizer`.\n",
    "\n",
    "Hint:\n",
    " - [`sklearn.feature_extraction.text.TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    max_features=100 # LINE TO BE REMOVED FOR STUDENTS\n",
    "    )\n",
    "\n",
    "# Apply the TfidfVectorizer and check the results on some rows\n",
    "tfidf_vectorizer.fit(x_train)\n",
    "\n",
    "x_train_features = tfidf_vectorizer.transform(x_train).toarray()\n",
    "x_test_features = tfidf_vectorizer.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f58ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503e3e3",
   "metadata": {},
   "source": [
    "You can now combine the vectorizer to a logistic regression in a single pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02065a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    max_features=100\n",
    "    )\n",
    "\n",
    "# Initialize the logistic regression\n",
    "logit = LogisticRegression(solver='lbfgs', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Combine them into a Pipeline object\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('vectorizer', tfidf_vectorizer), # LINE TO BE REMOVED FOR STUDENTS\n",
    "    ('model', logit)]) # LINE TO BE REMOVED FOR STUDENTS\n",
    "\n",
    "# Fit the Pipeline\n",
    "pipeline_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17007c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_tfidf = pipeline_tfidf.predict(x_test)\n",
    "\n",
    "# Evaluate the second model\n",
    "print(f\"Confusion matrix of the first model: \\n {confusion_matrix(y_test, y_pred_tfidf)}\")\n",
    "print(f\"second model precision : {precision_score(y_pred_tfidf, y_test):.{3}f}%\")\n",
    "print(f\"second model recall    : {recall_score(y_pred_tfidf, y_test)}%\")\n",
    "print(f\"second model f1 score  : {f1_score(y_pred_tfidf, y_test):.{3}f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b044d2",
   "metadata": {},
   "source": [
    "### 6.4 Optimize the model\n",
    "\n",
    "You can now try to optimize the model by changing a lot of parameters:\n",
    "- Take more reviews in input\n",
    "- Increase the `max_features` parameter\n",
    "- Remove the most frequent words\n",
    "- Try adding n-grams to the vectorizer\n",
    "- Improve the text cleaning\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05865690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
